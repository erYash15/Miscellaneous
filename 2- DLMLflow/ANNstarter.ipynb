{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/mlflow/mlflow-example/refs/heads/master/wine-quality.csv\")\n",
    "\n",
    "# Train Test Split\n",
    "train,test = train_test_split(data, test_size=0.5, random_state=42)\n",
    "train_x = train.drop(\"quality\", axis = 1).values\n",
    "train_y = train[['quality']].values.ravel()\n",
    "test_x = test.drop(\"quality\", axis = 1).values\n",
    "test_y = test[['quality']].values.ravel()\n",
    "\n",
    "# Train Valid Split\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  [Tensor('float64', (-1, 11))]\n",
       "outputs: \n",
       "  [Tensor('int64', (-1,))]\n",
       "params: \n",
       "  None"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singature = infer_signature(train_x, train_y)\n",
    "singature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANN Model\n",
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_dim, mean, var):\n",
    "        super(ANNModel, self).__init__()\n",
    "        self.norm = nn.BatchNorm1d(input_dim)\n",
    "\n",
    "        for param in self.norm.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.norm.running_mean = mean\n",
    "        self.norm.running_var = var\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(params, epochs, train_x, train_y, valid_x, valid_y, test_x, test_y):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    mean=torch.tensor(np.mean(train_x,axis=0), dtype=torch.float32)\n",
    "    var=torch.tensor(np.var(train_x,axis=0), dtype=torch.float32)\n",
    "\n",
    "    # Convert NumPy arrays to PyTorch tensors\n",
    "    train_x, train_y = torch.tensor(train_x, dtype=torch.float32), torch.tensor(train_y, dtype=torch.float32).view(-1, 1)\n",
    "    valid_x, valid_y = torch.tensor(valid_x, dtype=torch.float32), torch.tensor(valid_y, dtype=torch.float32).view(-1, 1)\n",
    "    test_x, test_y = torch.tensor(test_x, dtype=torch.float32), torch.tensor(test_y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(TensorDataset(train_x, train_y), batch_size=64, shuffle=True)\n",
    "    valid_loader = DataLoader(TensorDataset(valid_x, valid_y), batch_size=64, shuffle=False)\n",
    "\n",
    "    # Initialize model\n",
    "    model = ANNModel(train_x.shape[1], mean, var).to(device)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=params[\"lr\"], momentum=params[\"momentum\"])\n",
    "\n",
    "    # Training loop with MLflow tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()  \n",
    "\n",
    "\n",
    "            train_loss = running_loss/len(train_loader)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}\")\n",
    "                    # Log metrics with step=epoch (important for graphs)\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in valid_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        eval_rmse = (total_loss / len(valid_loader)) ** 0.5\n",
    "        \n",
    "        # Log parameters and results\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"eval_rmse\", eval_rmse)\n",
    "        \n",
    "        # Save model using MLflow\n",
    "        # Example input tensor (a batch of zeros with the same shape as one input sample)\n",
    "        input_example = torch.zeros(1, train_x.shape[1], dtype=torch.float32).numpy()\n",
    "        mlflow.pytorch.log_model(model, \"model\", input_example=input_example)\n",
    "        \n",
    "        return {\"loss\": eval_rmse, \"status\": \"SUCCESS\", \"model\": model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # MLflow will track the parameters and results for each run\n",
    "    result = train_model(\n",
    "        params,\n",
    "        epochs=3,\n",
    "        train_x=train_x,\n",
    "        train_y=train_y,\n",
    "        valid_x=valid_x,\n",
    "        valid_y=valid_y,\n",
    "        test_x=test_x,\n",
    "        test_y=test_y,\n",
    "    )\n",
    "    return {\"loss\": result[\"loss\"], \"status\": STATUS_OK, \"model\":result[\"model\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective({\"lr\":1e-1,\"momentum\":0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={\n",
    "    \"lr\":hp.loguniform(\"lr\",np.log(1e-5),np.log(1e-1)),\n",
    "    \"momentum\":hp.uniform(\"momentum\",0.0,1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 29.0480                             \n",
      "Epoch 2/3, Loss: 21.5140                             \n",
      "Epoch 3/3, Loss: 15.6919                             \n",
      "  0%|          | 0/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  12%|#2        | 1/8 [00:00<00:00, 4128.25it/s]\n",
      "Downloading artifacts:  25%|##5       | 2/8 [00:00<00:00, 1944.06it/s]\n",
      "Downloading artifacts:  38%|###7      | 3/8 [00:00<00:00, 1511.10it/s]\n",
      "Downloading artifacts:  50%|#####     | 4/8 [00:00<00:00, 1397.64it/s]\n",
      "Downloading artifacts:  62%|######2   | 5/8 [00:00<00:00, 1369.26it/s]\n",
      "Downloading artifacts:  75%|#######5  | 6/8 [00:00<00:00, 1261.57it/s]\n",
      "Downloading artifacts:  88%|########7 | 7/8 [00:00<00:00, 1262.04it/s]\n",
      "Downloading artifacts: 100%|##########| 8/8 [00:00<00:00, 1267.98it/s]\n",
      "Downloading artifacts: 100%|##########| 8/8 [00:00<00:00, 1175.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run carefree-cow-92 at: http://127.0.0.1:5000/#/experiments/267861629433437767/runs/99918ec6463a4d3680da4418b2c9b2ab\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/267861629433437767\n",
      "\n",
      "Epoch 1/3, Loss: 7.8495                                                       \n",
      "Epoch 2/3, Loss: 1.3019                                                       \n",
      "Epoch 3/3, Loss: 1.1140                                                       \n",
      " 33%|███▎      | 1/3 [00:04<00:09,  4.73s/trial, best loss: 3.648903810814486]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  12%|#2        | 1/8 [00:00<00:00, 2538.92it/s]\n",
      "Downloading artifacts:  25%|##5       | 2/8 [00:00<00:00, 1523.26it/s]\n",
      "Downloading artifacts:  38%|###7      | 3/8 [00:00<00:00, 1429.88it/s]\n",
      "Downloading artifacts:  50%|#####     | 4/8 [00:00<00:00, 1316.38it/s]\n",
      "Downloading artifacts:  62%|######2   | 5/8 [00:00<00:00, 1264.72it/s]\n",
      "Downloading artifacts:  75%|#######5  | 6/8 [00:00<00:00, 1264.80it/s]\n",
      "Downloading artifacts:  88%|########7 | 7/8 [00:00<00:00, 1282.72it/s]\n",
      "Downloading artifacts: 100%|##########| 8/8 [00:00<00:00, 1280.80it/s]\n",
      "Downloading artifacts: 100%|##########| 8/8 [00:00<00:00, 1168.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run sincere-yak-377 at: http://127.0.0.1:5000/#/experiments/267861629433437767/runs/70ccc10c64a243dba177a624ff6be987\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/267861629433437767 \n",
      "\n",
      "Epoch 1/3, Loss: 23.8440                                                       \n",
      "Epoch 2/3, Loss: 9.8899                                                        \n",
      "Epoch 3/3, Loss: 4.2482                                                        \n",
      " 67%|██████▋   | 2/3 [00:09<00:04,  4.68s/trial, best loss: 1.1260064543753778]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  12%|#2        | 1/8 [00:00<00:00, 3708.49it/s]\n",
      "Downloading artifacts:  25%|##5       | 2/8 [00:00<00:00, 1901.75it/s]\n",
      "Downloading artifacts:  38%|###7      | 3/8 [00:00<00:00, 1462.62it/s]\n",
      "Downloading artifacts:  50%|#####     | 4/8 [00:00<00:00, 1424.57it/s]\n",
      "Downloading artifacts:  62%|######2   | 5/8 [00:00<00:00, 1355.54it/s]\n",
      "Downloading artifacts:  75%|#######5  | 6/8 [00:00<00:00, 1344.54it/s]\n",
      "Downloading artifacts:  88%|########7 | 7/8 [00:00<00:00, 1305.36it/s]\n",
      "Downloading artifacts: 100%|##########| 8/8 [00:00<00:00, 1299.15it/s]\n",
      "Downloading artifacts: 100%|##########| 8/8 [00:00<00:00, 1200.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run receptive-ray-716 at: http://127.0.0.1:5000/#/experiments/267861629433437767/runs/fdc1cf022a3c41cfb603697899c4ff89\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/267861629433437767  \n",
      "\n",
      "100%|██████████| 3/3 [00:14<00:00,  4.69s/trial, best loss: 1.1260064543753778]\n",
      "Best hyperparameters: {'lr': np.float64(0.0045974588038298625), 'momentum': np.float64(0.49524440274275205)}\n",
      "Best eval rmse 1.1260064543753778\n",
      "🏃 View run overjoyed-sponge-526 at: http://127.0.0.1:5000/#/experiments/267861629433437767/runs/7b695ab2d3c24dadab4ed407c4b3dbad\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/267861629433437767\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    # Conduct the hyperparamter search using hyperopt\n",
    "    # Run the optimization\n",
    "    trials = Trials()\n",
    "    best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=3, trials=trials)\n",
    "\n",
    "    # Sort trials based on the loss (lower is better)\n",
    "    best_trial = sorted(trials.results, key=lambda x: x['loss'])[0]  # Best trial\n",
    "    best_model = best_trial['model']  # Extract the best model\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.pytorch.log_model(best_model, 'best_model', signature=singature)\n",
    "\n",
    "    # Print out the best params and loss\n",
    "    print(\"Best hyperparameters:\", best_params)\n",
    "    print(\"Best eval rmse\", best_trial['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 138.97it/s]\n",
      "2025/03/30 18:58:04 INFO mlflow.models.python_api: It is highly recommended to use `uv` as the environment manager for predicting with MLflow models as its performance is significantly better than other environment managers. Run `pip install uv` to install uv. See https://docs.astral.sh/uv/getting-started/installation for other installation methods.\n",
      "Downloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 156.76it/s] \n",
      "2025/03/30 18:58:04 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n",
      "Downloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 145.12it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [[200.72340393066406]]}"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "model_uri = 'runs:/4c26c217e33347419ca1bdc04094c75a/model'\n",
    "# This is the input example logged with the model\n",
    "pyfunc_model = mlflow.pyfunc.load_model(model_uri)\n",
    "input_data = pyfunc_model.input_example\n",
    "\n",
    "# Verify the model with the provided input data using the logged dependencies.\n",
    "# For more details, refer to:\n",
    "# https://mlflow.org/docs/latest/models.html#validate-models-before-deployment\n",
    "mlflow.models.predict(\n",
    "    model_uri=model_uri,\n",
    "    input_data=input_data,\n",
    "    env_manager=\"local\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
